{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Analysis \n",
    "\n",
    "### Steps\n",
    "<ol type=\"1\">\n",
    "    <li>Load the dataset</li>\n",
    "    <li>Clean and encode Dataset</li>\n",
    "    <li>Split Dataset 80:20</li>\n",
    "    <li>Tokenize and Pad/Truncate Reviews</li>\n",
    "    <li>Bulid LSTM Model</li>\n",
    "    <li>Train and Test</li>\n",
    "</ol>\n",
    "\n",
    "<hr>\n",
    "<i>Import all the libraries needed</i>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd    # to load dataset\n",
    "import numpy as np     # for mathematic equation\n",
    "from nltk.corpus import stopwords   # to get collection of stopwords\n",
    "from sklearn.model_selection import train_test_split       # for splitting dataset\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer  # to encode text to int\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences   # to do padding or truncating\n",
    "from tensorflow.keras.models import Sequential     # the model\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense # layers of the architecture\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint   # save model\n",
    "from tensorflow.keras.models import load_model   # load saved model\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<i>Show the datset we are using</i>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                  review sentiment\n",
      "0      One of the other reviewers has mentioned that ...  positive\n",
      "1      A wonderful little production. <br /><br />The...  positive\n",
      "2      I thought this was a wonderful way to spend ti...  positive\n",
      "3      Basically there's a family where a little boy ...  negative\n",
      "4      Petter Mattei's \"Love in the Time of Money\" is...  positive\n",
      "...                                                  ...       ...\n",
      "49995  I thought this movie did a down right good job...  positive\n",
      "49996  Bad plot, bad dialogue, bad acting, idiotic di...  negative\n",
      "49997  I am a Catholic taught in parochial elementary...  negative\n",
      "49998  I'm going to have to disagree with the previou...  negative\n",
      "49999  No one expects the Star Trek movies to be high...  negative\n",
      "\n",
      "[50000 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('IMDB Dataset.csv')\n",
    "\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<b>Stop Word</b> is a commonly used words in a sentence, usually a search engine is programmed to ignore this words (i.e. \"the\", \"a\", \"an\", \"of\", etc.)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "english_stops = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "### Load and Clean Dataset\n",
    "\n",
    "In the original dataset, the reviews are still dirty. There are still html tags, numbers, uppercase, and punctuations. We remove all that in this step and encode the sentiments into integers (0 and 1). Where 0 is for negative sentiments and 1 is for positive sentiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reviews\n",
      "0        [one, reviewers, mentioned, watching, oz, epis...\n",
      "1        [a, wonderful, little, production, the, filmin...\n",
      "2        [i, thought, wonderful, way, spend, time, hot,...\n",
      "3        [basically, family, little, boy, jake, thinks,...\n",
      "4        [petter, mattei, love, time, money, visually, ...\n",
      "                               ...                        \n",
      "49995    [i, thought, movie, right, good, job, it, crea...\n",
      "49996    [bad, plot, bad, dialogue, bad, acting, idioti...\n",
      "49997    [i, catholic, taught, parochial, elementary, s...\n",
      "49998    [i, going, disagree, previous, comment, side, ...\n",
      "49999    [no, one, expects, star, trek, movies, high, a...\n",
      "Name: review, Length: 50000, dtype: object \n",
      "\n",
      "Sentiment\n",
      "0        1\n",
      "1        1\n",
      "2        1\n",
      "3        0\n",
      "4        1\n",
      "        ..\n",
      "49995    1\n",
      "49996    0\n",
      "49997    0\n",
      "49998    0\n",
      "49999    0\n",
      "Name: sentiment, Length: 50000, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "def load_dataset():\n",
    "    df = pd.read_csv('IMDB Dataset.csv')\n",
    "    x_data = df['review']       # Reviews/Input\n",
    "    y_data = df['sentiment']    # Sentiment/Output\n",
    "\n",
    "    # PRE-PROCESS REVIEW\n",
    "    x_data = x_data.replace({'<.*?>': ''}, regex = True)          # remove html tag\n",
    "    x_data = x_data.replace({'[^A-Za-z]': ' '}, regex = True)     # remove non alphabet\n",
    "    x_data = x_data.apply(lambda review: [w for w in review.split() if w not in english_stops])  # remove stop words\n",
    "    x_data = x_data.apply(lambda review: [w.lower() for w in review])   # lower case\n",
    "    \n",
    "    # ENCODE SENTIMENT -> 0 & 1\n",
    "    y_data = y_data.replace('positive', 1)\n",
    "    y_data = y_data.replace('negative', 0)\n",
    "\n",
    "    return x_data, y_data\n",
    "\n",
    "x_data, y_data = load_dataset()\n",
    "\n",
    "print('Reviews')\n",
    "print(x_data, '\\n')\n",
    "print('Sentiment')\n",
    "print(y_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "### Split Dataset\n",
    "In this work, I decided to split the data into 80% of Training and 20% of Testing set using <b>train_test_split</b> method from Scikit-Learn. By using this method, it automatically shuffles the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Set\n",
      "8929     [i, remember, film, fondly, seeing, theatre, i...\n",
      "200      [interesting, short, television, movie, descri...\n",
      "21346    [ed, wood, eclipsed, becomes, orson, welles, t...\n",
      "38239    [in, rapid, economic, development, china, resu...\n",
      "49685    [i, always, loved, old, movies, one, top, ten,...\n",
      "                               ...                        \n",
      "48028    [from, start, know, movie, end, it, full, clic...\n",
      "23085    [i, saw, peter, watkin, culloden, the, war, ga...\n",
      "47004    [wonderland, fascinating, film, chronicling, x...\n",
      "11490    [this, movie, travels, farther, gunshots, kiss...\n",
      "2247     [that, answer, the, question, what, single, re...\n",
      "Name: review, Length: 40000, dtype: object \n",
      "\n",
      "5424     [this, movie, quite, possibly, one, horrible, ...\n",
      "41503    [s, i, c, k, really, stands, so, incredibly, c...\n",
      "47855    [it, where, poppa, the, groove, tube, putney, ...\n",
      "9922     [i, know, loved, movie, years, old, now, watch...\n",
      "26229    [this, picture, hit, movie, screens, june, th,...\n",
      "                               ...                        \n",
      "37234    [when, one, stops, recollect, upon, frequent, ...\n",
      "10362    [this, film, takes, another, time, different, ...\n",
      "213      [normally, i, like, series, they, predictable,...\n",
      "37487    [ok, i, american, humble, scottish, opinion, s...\n",
      "26782    [i, must, first, mention, group, mates, often,...\n",
      "Name: review, Length: 10000, dtype: object \n",
      "\n",
      "Test Set\n",
      "8929     1\n",
      "200      0\n",
      "21346    0\n",
      "38239    1\n",
      "49685    1\n",
      "        ..\n",
      "48028    0\n",
      "23085    1\n",
      "47004    1\n",
      "11490    1\n",
      "2247     0\n",
      "Name: sentiment, Length: 40000, dtype: int64 \n",
      "\n",
      "5424     0\n",
      "41503    0\n",
      "47855    1\n",
      "9922     0\n",
      "26229    0\n",
      "        ..\n",
      "37234    1\n",
      "10362    1\n",
      "213      1\n",
      "37487    0\n",
      "26782    0\n",
      "Name: sentiment, Length: 10000, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x_data, y_data, test_size = 0.2)\n",
    "\n",
    "print('Train Set')\n",
    "print(x_train, '\\n')\n",
    "print(x_test, '\\n')\n",
    "print('Test Set')\n",
    "print(y_train, '\\n')\n",
    "print(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<i>Function for getting the maximum review length (using mean)</i>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_max_length():\n",
    "    review_length = []\n",
    "    for review in x_train:\n",
    "        review_length.append(len(review))\n",
    "\n",
    "    return int(np.ceil(np.mean(review_length)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "### Tokenize and Pad/Truncate Reviews\n",
    "A Neural Network only accepts numeric data, so we need to encode the reviews. Tokenizer is used to encode the reviews into integers, where each unique word is automatically indexed.\n",
    "\n",
    "Each reviews has a different length, so we need to add padding (by adding 0) or truncating the words to the same length (in this case, it is the mean of all reviews length) using\n",
    "\n",
    "<b>post</b>, pad or truncate the words in the back of a sentence<br>\n",
    "<b>pre</b>, pad or truncate the words in front of a sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoded X Train\n",
      " [[    1   289     4 ...     0     0     0]\n",
      " [  129   239   588 ...     0     0     0]\n",
      " [ 1209  1544 18168 ...     0     0     0]\n",
      " ...\n",
      " [ 6821  1345     4 ...     0     0     0]\n",
      " [    8     3  3428 ...     0     0     0]\n",
      " [  143  1415     2 ...     0     0     0]] \n",
      "\n",
      "Encoded X Test\n",
      " [[    8     3    93 ...     0     0     0]\n",
      " [  614     1   859 ...     0     0     0]\n",
      " [    7  1072 18822 ...     0     0     0]\n",
      " ...\n",
      " [ 1916     1     6 ...     0     0     0]\n",
      " [  486     1   194 ...     0     0     0]\n",
      " [    1   113    23 ...     0     0     0]] \n",
      "\n",
      "Maximum review length:  130\n"
     ]
    }
   ],
   "source": [
    "# ENCODE REVIEW\n",
    "token = Tokenizer(lower=False)    # no need lower, because already lowered the data in load_data()\n",
    "token.fit_on_texts(x_train)\n",
    "x_train = token.texts_to_sequences(x_train)\n",
    "x_test = token.texts_to_sequences(x_test)\n",
    "\n",
    "max_length = get_max_length()\n",
    "\n",
    "x_train = pad_sequences(x_train, maxlen=max_length, padding='post', truncating='post')\n",
    "x_test = pad_sequences(x_test, maxlen=max_length, padding='post', truncating='post')\n",
    "\n",
    "total_words = len(token.word_index) + 1   # add 1 because of 0 padding\n",
    "\n",
    "print('Encoded X Train\\n', x_train, '\\n')\n",
    "print('Encoded X Test\\n', x_test, '\\n')\n",
    "print('Maximum review length: ', max_length)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "### Build Architecture/Model\n",
    "<b>Embedding Layer</b>: in simple terms, it creates word vectors of each word in the <i>word_index</i> and group words that are related or have similar meaning by analyzing other words around them.\n",
    "\n",
    "<b>LSTM Layer</b>: to make a decision to keep or throw away data by considering the current input, previous output, and previous memory. There are some important components in LSTM.\n",
    "<ul>\n",
    "    <li><b>Forget Gate</b>, decides information is to be kept or thrown away</li>\n",
    "    <li><b>Input Gate</b>, updates cell state by passing previous output and current input into sigmoid activation function</li>\n",
    "    <li><b>Cell State</b>, calculate new cell state, it is multiplied by forget vector (drop value if multiplied by a near 0), add it with the output from input gate to update the cell state value.</li>\n",
    "    <li><b>Ouput Gate</b>, decides the next hidden state and used for predictions</li>\n",
    "</ul>\n",
    "\n",
    "<b>Dense Layer</b>: compute the input with the weight matrix and bias (optional), and using an activation function. I use <b>Sigmoid</b> activation function for this work because the output is only 0 or 1.\n",
    "\n",
    "The optimizer is <b>Adam</b> and the loss function is <b>Binary Crossentropy</b> because again the output is only 0 and 1, which is a binary number."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 130, 32)           2954208   \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 64)                24832     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 2,979,105\n",
      "Trainable params: 2,979,105\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# ARCHITECTURE\n",
    "EMBED_DIM = 32\n",
    "LSTM_OUT = 64\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(total_words, EMBED_DIM, input_length = max_length))\n",
    "model.add(LSTM(LSTM_OUT))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "### Training\n",
    "For training We only need to fit our <b>x_train</b> (input) and <b>y_train</b> (output/label) data. For this training, mini-batch learning method with a <b>batch_size</b> of <i>32</i> and <i>100</i> <b>epochs</b> is used.\n",
    "\n",
    "Also, I added a callback called **checkpoint** to save the model locally for every epoch if its accuracy improved from the previous epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = ModelCheckpoint(\n",
    "    'models/LSTM.h5',\n",
    "    monitor='accuracy',\n",
    "    save_best_only=True,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1250/1250 [==============================] - ETA: 0s - loss: 0.6704 - accuracy: 0.5883\n",
      "Epoch 00001: accuracy improved from -inf to 0.58830, saving model to models/LSTM.h5\n",
      "1250/1250 [==============================] - 145s 116ms/step - loss: 0.6704 - accuracy: 0.5883\n",
      "Epoch 2/100\n",
      "1250/1250 [==============================] - ETA: 0s - loss: 0.6529 - accuracy: 0.6097\n",
      "Epoch 00002: accuracy improved from 0.58830 to 0.60965, saving model to models/LSTM.h5\n",
      "1250/1250 [==============================] - 142s 114ms/step - loss: 0.6529 - accuracy: 0.6097\n",
      "Epoch 3/100\n",
      "1250/1250 [==============================] - ETA: 0s - loss: 0.5323 - accuracy: 0.7455\n",
      "Epoch 00003: accuracy improved from 0.60965 to 0.74553, saving model to models/LSTM.h5\n",
      "1250/1250 [==============================] - 149s 119ms/step - loss: 0.5323 - accuracy: 0.7455\n",
      "Epoch 4/100\n",
      "1250/1250 [==============================] - ETA: 0s - loss: 0.4411 - accuracy: 0.8079\n",
      "Epoch 00004: accuracy improved from 0.74553 to 0.80785, saving model to models/LSTM.h5\n",
      "1250/1250 [==============================] - 137s 110ms/step - loss: 0.4411 - accuracy: 0.8079\n",
      "Epoch 5/100\n",
      "1250/1250 [==============================] - ETA: 0s - loss: 0.4356 - accuracy: 0.8363\n",
      "Epoch 00005: accuracy improved from 0.80785 to 0.83627, saving model to models/LSTM.h5\n",
      "1250/1250 [==============================] - 127s 102ms/step - loss: 0.4356 - accuracy: 0.8363\n",
      "Epoch 6/100\n",
      "1250/1250 [==============================] - ETA: 0s - loss: 0.3950 - accuracy: 0.8452\n",
      "Epoch 00006: accuracy improved from 0.83627 to 0.84522, saving model to models/LSTM.h5\n",
      "1250/1250 [==============================] - 127s 102ms/step - loss: 0.3950 - accuracy: 0.8452\n",
      "Epoch 7/100\n",
      "1250/1250 [==============================] - ETA: 0s - loss: 0.4748 - accuracy: 0.7687\n",
      "Epoch 00007: accuracy did not improve from 0.84522\n",
      "1250/1250 [==============================] - 127s 102ms/step - loss: 0.4748 - accuracy: 0.7687\n",
      "Epoch 8/100\n",
      "1250/1250 [==============================] - ETA: 0s - loss: 0.3567 - accuracy: 0.8561\n",
      "Epoch 00008: accuracy improved from 0.84522 to 0.85607, saving model to models/LSTM.h5\n",
      "1250/1250 [==============================] - 128s 102ms/step - loss: 0.3567 - accuracy: 0.8561\n",
      "Epoch 9/100\n",
      "1250/1250 [==============================] - ETA: 0s - loss: 0.3110 - accuracy: 0.8890\n",
      "Epoch 00009: accuracy improved from 0.85607 to 0.88898, saving model to models/LSTM.h5\n",
      "1250/1250 [==============================] - 125s 100ms/step - loss: 0.3110 - accuracy: 0.8890\n",
      "Epoch 10/100\n",
      "1250/1250 [==============================] - ETA: 0s - loss: 0.3146 - accuracy: 0.8842\n",
      "Epoch 00010: accuracy did not improve from 0.88898\n",
      "1250/1250 [==============================] - 125s 100ms/step - loss: 0.3146 - accuracy: 0.8842\n",
      "Epoch 11/100\n",
      "1250/1250 [==============================] - ETA: 0s - loss: 0.2130 - accuracy: 0.9229\n",
      "Epoch 00011: accuracy improved from 0.88898 to 0.92287, saving model to models/LSTM.h5\n",
      "1250/1250 [==============================] - 125s 100ms/step - loss: 0.2130 - accuracy: 0.9229\n",
      "Epoch 12/100\n",
      "1250/1250 [==============================] - ETA: 0s - loss: 0.1556 - accuracy: 0.9467\n",
      "Epoch 00012: accuracy improved from 0.92287 to 0.94675, saving model to models/LSTM.h5\n",
      "1250/1250 [==============================] - 125s 100ms/step - loss: 0.1556 - accuracy: 0.9467\n",
      "Epoch 13/100\n",
      "1250/1250 [==============================] - ETA: 0s - loss: 0.1158 - accuracy: 0.9631\n",
      "Epoch 00013: accuracy improved from 0.94675 to 0.96305, saving model to models/LSTM.h5\n",
      "1250/1250 [==============================] - 126s 101ms/step - loss: 0.1158 - accuracy: 0.9631\n",
      "Epoch 14/100\n",
      "1250/1250 [==============================] - ETA: 0s - loss: 0.0857 - accuracy: 0.9740\n",
      "Epoch 00014: accuracy improved from 0.96305 to 0.97400, saving model to models/LSTM.h5\n",
      "1250/1250 [==============================] - 130s 104ms/step - loss: 0.0857 - accuracy: 0.9740\n",
      "Epoch 15/100\n",
      "1250/1250 [==============================] - ETA: 0s - loss: 0.0628 - accuracy: 0.9821\n",
      "Epoch 00015: accuracy improved from 0.97400 to 0.98210, saving model to models/LSTM.h5\n",
      "1250/1250 [==============================] - 126s 101ms/step - loss: 0.0628 - accuracy: 0.9821\n",
      "Epoch 16/100\n",
      "1250/1250 [==============================] - ETA: 0s - loss: 0.0445 - accuracy: 0.9887\n",
      "Epoch 00016: accuracy improved from 0.98210 to 0.98875, saving model to models/LSTM.h5\n",
      "1250/1250 [==============================] - 125s 100ms/step - loss: 0.0445 - accuracy: 0.9887\n",
      "Epoch 17/100\n",
      "1250/1250 [==============================] - ETA: 0s - loss: 0.0336 - accuracy: 0.9919\n",
      "Epoch 00017: accuracy improved from 0.98875 to 0.99190, saving model to models/LSTM.h5\n",
      "1250/1250 [==============================] - 126s 100ms/step - loss: 0.0336 - accuracy: 0.9919\n",
      "Epoch 18/100\n",
      "1250/1250 [==============================] - ETA: 0s - loss: 0.0256 - accuracy: 0.9941\n",
      "Epoch 00018: accuracy improved from 0.99190 to 0.99410, saving model to models/LSTM.h5\n",
      "1250/1250 [==============================] - 127s 102ms/step - loss: 0.0256 - accuracy: 0.9941\n",
      "Epoch 19/100\n",
      "1250/1250 [==============================] - ETA: 0s - loss: 0.0184 - accuracy: 0.9961\n",
      "Epoch 00019: accuracy improved from 0.99410 to 0.99605, saving model to models/LSTM.h5\n",
      "1250/1250 [==============================] - 128s 102ms/step - loss: 0.0184 - accuracy: 0.9961\n",
      "Epoch 20/100\n",
      "1250/1250 [==============================] - ETA: 0s - loss: 0.0137 - accuracy: 0.9971\n",
      "Epoch 00020: accuracy improved from 0.99605 to 0.99708, saving model to models/LSTM.h5\n",
      "1250/1250 [==============================] - 127s 101ms/step - loss: 0.0137 - accuracy: 0.9971\n",
      "Epoch 21/100\n",
      "1250/1250 [==============================] - ETA: 0s - loss: 0.0133 - accuracy: 0.9974\n",
      "Epoch 00021: accuracy improved from 0.99708 to 0.99740, saving model to models/LSTM.h5\n",
      "1250/1250 [==============================] - 127s 102ms/step - loss: 0.0133 - accuracy: 0.9974\n",
      "Epoch 22/100\n",
      "1250/1250 [==============================] - ETA: 0s - loss: 0.0091 - accuracy: 0.9982\n",
      "Epoch 00022: accuracy improved from 0.99740 to 0.99820, saving model to models/LSTM.h5\n",
      "1250/1250 [==============================] - 126s 101ms/step - loss: 0.0091 - accuracy: 0.9982\n",
      "Epoch 23/100\n",
      "1250/1250 [==============================] - ETA: 0s - loss: 0.0062 - accuracy: 0.9990\n",
      "Epoch 00023: accuracy improved from 0.99820 to 0.99895, saving model to models/LSTM.h5\n",
      "1250/1250 [==============================] - 127s 102ms/step - loss: 0.0062 - accuracy: 0.9990\n",
      "Epoch 24/100\n",
      "1250/1250 [==============================] - ETA: 0s - loss: 0.0095 - accuracy: 0.9975\n",
      "Epoch 00024: accuracy did not improve from 0.99895\n",
      "1250/1250 [==============================] - 128s 102ms/step - loss: 0.0095 - accuracy: 0.9975\n",
      "Epoch 25/100\n",
      "1250/1250 [==============================] - ETA: 0s - loss: 0.0070 - accuracy: 0.9982\n",
      "Epoch 00025: accuracy did not improve from 0.99895\n",
      "1250/1250 [==============================] - 126s 100ms/step - loss: 0.0070 - accuracy: 0.9982\n",
      "Epoch 26/100\n",
      "1250/1250 [==============================] - ETA: 0s - loss: 0.0034 - accuracy: 0.9993\n",
      "Epoch 00026: accuracy improved from 0.99895 to 0.99932, saving model to models/LSTM.h5\n",
      "1250/1250 [==============================] - 124s 99ms/step - loss: 0.0034 - accuracy: 0.9993\n",
      "Epoch 27/100\n",
      "1250/1250 [==============================] - ETA: 0s - loss: 0.0014 - accuracy: 0.9998\n",
      "Epoch 00027: accuracy improved from 0.99932 to 0.99977, saving model to models/LSTM.h5\n",
      "1250/1250 [==============================] - 125s 100ms/step - loss: 0.0014 - accuracy: 0.9998\n",
      "Epoch 28/100\n",
      " 947/1250 [=====================>........] - ETA: 30s - loss: 0.0028 - accuracy: 0.9993"
     ]
    }
   ],
   "source": [
    "model.fit(x_train, y_train, batch_size = 32, epochs = 100, callbacks=[checkpoint])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "### Testing\n",
    "To evaluate the model, we need to predict the sentiment using our <b>x_test</b> data and comparing the predictions with <b>y_test</b> (expected output) data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-10-ca304a47a1a9>:1: Sequential.predict_classes (from tensorflow.python.keras.engine.sequential) is deprecated and will be removed after 2021-01-01.\n",
      "Instructions for updating:\n",
      "Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "Correct Prediction: 5031\n",
      "Wrong Prediction: 4969\n",
      "Accuracy: 50.31\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict_classes(x_test, batch_size = 32)\n",
    "\n",
    "true = 0\n",
    "for i, y in enumerate(y_test):\n",
    "    if y == y_pred[i]:\n",
    "        true += 1\n",
    "\n",
    "print('Correct Prediction: {}'.format(true))\n",
    "print('Wrong Prediction: {}'.format(len(y_pred) - true))\n",
    "print('Accuracy: {}'.format(true/len(y_pred)*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Load Saved Model\n",
    "\n",
    "Load saved model and use it to predict a  statement's sentiment (positive or negative)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model = load_model('models/LSTM.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Receives a review as an input to be predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Movie Review: good movie a must watch \n"
     ]
    }
   ],
   "source": [
    "review = str(input('Statement: '))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Process the input string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned:  good movie a must watch \n",
      "Filtered:  ['good movie must watch ']\n"
     ]
    }
   ],
   "source": [
    "# Pre-process input\n",
    "regex = re.compile(r'[^a-zA-Z\\s]')\n",
    "review = regex.sub('', review)\n",
    "print('Cleaned: ', review)\n",
    "\n",
    "words = review.split(' ')\n",
    "filtered = [w for w in words if w not in english_stops]\n",
    "filtered = ' '.join(filtered)\n",
    "filtered = [filtered.lower()]\n",
    "\n",
    "print('Filtered: ', filtered)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tokenize again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  9   3 114  33   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0]]\n"
     ]
    }
   ],
   "source": [
    "tokenize_words = token.texts_to_sequences(filtered)\n",
    "tokenize_words = pad_sequences(tokenize_words, maxlen=max_length, padding='post', truncating='post')\n",
    "print(tokenize_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "calculate the output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.9996678]]\n"
     ]
    }
   ],
   "source": [
    "result = loaded_model.predict(tokenize_words)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the confidence score is close to 0, then the statement is **negative**. On the other hand, if the confidence score is close to 1, then the statement is **positive** . (0.5 is the threshhold here)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "positive\n"
     ]
    }
   ],
   "source": [
    "if result >= 0.5:\n",
    "    print('positive')\n",
    "else:\n",
    "    print('negative')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
